{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"1\"\n",
    "\n",
    "from tools import*\n",
    "from models import*\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from torch.autograd import Variable, Function\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch.nn as nn\n",
    "import nibabel as nib\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data_utils\n",
    "import torch.optim.lr_scheduler as schd  \n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "torch.backends.cudnn.benchmark=True \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch = 32\n",
    "task = \"classification\"\n",
    "iteration = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = \"/home/emy24/tadpole/data/\"\n",
    "xTrain, xVal, xTest, _, _, _ = preprocess(path,elim_sparse_feature=True, cutoff=0.60)\n",
    "xTrain, xVal, xTest = make_list(path, xTrain, xVal, xTest)\n",
    "\n",
    "# xTrain.to_pickle(\"/home/emy24/tadpole/data/xTrain_pd_60\")\n",
    "# xVal.to_pickle(\"/home/emy24/tadpole/data/xVal_pd_60\")\n",
    "# xTest.to_pickle(\"/home/emy24/tadpole/data/xTest_pd_60\")\n",
    "\n",
    "# xTrain = pd.read_pickle(\"/home/emy24/tadpole/data/xTrain_pd_60\")\n",
    "# xVal = pd.read_pickle(\"/home/emy24/tadpole/data/xVal_pd_60\")\n",
    "# xTest = pd.read_pickle(\"/home/emy24/tadpole/data/xTest_pd_60\")\n",
    "# xTrain, xVal, xTest = make_list(path, xTrain, xVal, xTest)\n",
    "\n",
    "xTrain = get_matrix(xTrain)\n",
    "xTrain, xTrain_seq= get_pad(xTrain)\n",
    "\n",
    "xVal = get_matrix(xVal)\n",
    "xVal, xVal_seq= get_pad(xVal)\n",
    "\n",
    "xTest = get_matrix(xTest)\n",
    "xTest, xTest_seq= get_pad(xTest)\n",
    "\n",
    "\"\"\"Load Target\"\"\"\n",
    "\n",
    "#yTrain\n",
    "datapath = \"/home/emy24/tadpole/data/TADPOLE_TargetData_train.csv\"\n",
    "resampled_train, orig_dates_train = resample_data(datapath, interpolation = True)\n",
    "adas, ventricle, mmse = get_average(resampled_train)\n",
    "yTrain = get_standarize(resampled_train, adas, ventricle, mmse)\n",
    "yTrain = get_features(yTrain, task)\n",
    "yTrain = [yTrain for _, yTrain in yTrain.groupby(\"PTID_Key\")]\n",
    "yTrain = get_matrix(yTrain)\n",
    "yTrain, yTrain_seq= get_pad(yTrain)\n",
    "\n",
    "#yVal\n",
    "datapath = \"/home/emy24/tadpole/data/TADPOLE_TargetData_test.csv\"\n",
    "resampled_val, orig_dates_val = resample_data(datapath, interpolation = True)\n",
    "yVal = get_standarize(resampled_val, adas, ventricle, mmse)\n",
    "yVal = get_features(yVal, task)\n",
    "yVal = [yVal for _, yVal in yVal.groupby(\"PTID_Key\")]\n",
    "yVal = get_matrix(yVal)\n",
    "yVal, yVal_seq= get_pad(yVal)\n",
    "\n",
    "#yTest\n",
    "datapath = \"/home/emy24/tadpole/data/TADPOLE_PredictTargetData_valid.csv\"\n",
    "resampled_test, orig_dates_test = resample_data(datapath, interpolation = True)\n",
    "resampled_test = resampled_test.fillna(0)\n",
    "yTest = get_standarize(resampled_test, adas, ventricle, mmse)\n",
    "yTest = get_features(yTest, task)\n",
    "yTest = [yTest for _, yTest in yTest.groupby(\"PTID_Key\")]\n",
    "yTest = get_matrix(yTest)\n",
    "yTest, yTest_seq= get_pad(yTest)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def masked_loss(predicted, target, sequence, time_step):\n",
    "    \"\"\"\n",
    "    sequence: is the total numbers of visit from a patient\n",
    "    time_step: is the current visit\n",
    "    ----\n",
    "    ind: indicates whether we have information about the patient at this time step\n",
    "    k: number of elements in M that we actually care/have information. \n",
    "    loss: (1/k)*sum(ind*M)\n",
    "    Note:\n",
    "    squeeze at the beggining is to make sure to have a nxm matrix instead of a 3d tensor\n",
    "    the unsqueze thing in loss is just to make the matrix have the correct format for bmm function\n",
    "    \"\"\"\n",
    "    predicted = predicted.squeeze()\n",
    "    target = target.squeeze()\n",
    "    ind = ((time_step < np.asarray(sequence))*1).reshape(1,-1)\n",
    "    num_features = predicted.size(1)\n",
    "    k = np.sum(ind*num_features)\n",
    "    ind = Variable(torch.from_numpy(ind).cuda(), requires_grad = False).float()\n",
    "    M = torch.abs(predicted - target)\n",
    "    loss = torch.mul(torch.sum(torch.mm(ind, M)),(1/k))\n",
    "    return loss\n",
    "\n",
    "def get_accuracy(output, y_batch, t):\n",
    "    _, pred = torch.max(output.data, 1)\n",
    "    pred = pred.cpu().numpy()\n",
    "    label = y_batch[:,:,:]\n",
    "    label = label[:,t,-1]\n",
    "    correct = np.sum(pred==label)\n",
    "    \n",
    "    return 100*correct/label.shape[0]\n",
    "\n",
    "def more_visit(time_step,sequence):\n",
    "    return (np.sum((time_step < np.asarray(y_sequence))*1) > 0)\n",
    "\n",
    "\"\"\"GRU\"\"\"\n",
    "class GRU_Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, batch):\n",
    "        super(GRU_Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.batch = batch\n",
    "        self.gru = nn.GRU(input_size = input_size, hidden_size = hidden_size,\n",
    "                            batch_first=True, num_layers = num_layers)\n",
    "    \n",
    "    def forward(self, x, seq):\n",
    "        # Set initial states\n",
    "        h0 = Variable(torch.randn(self.num_layers, self.batch, self.hidden_size).float().cuda())\n",
    "        \n",
    "        # Forward propagate RNN\n",
    "        x = pack_padded_sequence(x, seq, batch_first=True)\n",
    "        out, hidden = self.gru(x)  \n",
    "        return out, hidden\n",
    "    \n",
    "\n",
    "class GRU_Decoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, batch, num_classes):\n",
    "        super(GRU_Decoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.batch = batch\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(in_features= self.hidden_size, out_features= self.hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(in_features= self.hidden_size, out_features= self.hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(in_features= self.hidden_size, out_features= 3))\n",
    " \n",
    "    def forward(self, x, h):    \n",
    "        # Forward propagate RNN\n",
    "        _, hidden = self.gru(x, h)\n",
    "        out = hidden[-1] #Grab the last output of the sequence\n",
    "        out = self.fc(out)  \n",
    "        return hidden, out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder = GRU_Encoder(input_size = 431 , hidden_size = 100, num_layers= 3, batch = batch )\n",
    "encoder = torch.nn.DataParallel(encoder)\n",
    "encoder.cuda()\n",
    "\n",
    "decoder = GRU_Decoder(input_size = 3 , hidden_size = 100, num_layers= 3, batch= batch, num_classes = 3)\n",
    "decoder = torch.nn.DataParallel(decoder)\n",
    "decoder.cuda()\n",
    "\n",
    "# Loss and Optimizer\n",
    "enc_opt = optim.Adam(encoder.parameters())\n",
    "dec_opt = optim.Adam(decoder.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "085b843c42a643dc90ae8f56ddbadfb4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "281f31db6d9c41c0b928dc62ea3d2e99"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26d467ebfcfc4ee2b41f8dc4f0c43038"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d76f1ebed8f84926ad058fd733b2b01a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de1b9cdd8d834a2484809ed920dc91fb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38eb9194424a4c7482b350647b4c5278"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eb19945cdfb4f3c9fd5ab18cdb072ec"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a38311611f9e43dfbd83003fdf472a1c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de61292844b643b4b59e9615f8ffbf9e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30b535c1ed1443d2a5bb3f999c73617a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f39270d3554649bd8ae7361d4759afea"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7853cec04c847c9b99222f25c94ee02"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f849ece41760482596544d53f6028431"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3332100f066141a29bc902db56c762f7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbe1d91442a443a1b8f4d60608f60342"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "093e7faf8e3e4b0ca0ba67c58bb2c288"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "094113adb9c649e0b3bd94e47d814521"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be8f5b7eabfe469fa7e279e682897195"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93e64858dbb04f07961db43e189b3d17"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abe24787acee4c2896e2057de4142275"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fdfc67df1d247778c6cf6351b6a0cd4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "beafaaf35b324d3c809293a2ab86ad58"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "443cbf39df0f4714b7f1dc9d89b498e5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59351fcb41844170984fc764df4b5f7d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adc6a1e25f304ca7bdebb31d902e748a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f689a11dc8534672b0b106a3ba108491"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e6ef998ac964af7b88ef9e66e558231"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c212234fbcc5445087c7304ff5b35da2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78d5dc834cfb407683698f6d004ae6b3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcc5d39c15f64dbeaf3f948936820686"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3484c24a50d4c4d99dd20047b133ff4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cec5d402b034a269cd73cd5d701bd19"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3c9c13811664fbb89e64669f7e83fe6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d17de6664c143ed93e5fc3f7bb7f8e1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1481b1b016741ccab8489971b8cad8e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6ef11b15cca4c32a857a9ff0570a442"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e897fa5fd1f4f368d034cb12ae9c884"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b2a0fdcb4d34802b8ca42f262561ce7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4a491514c4a434a8c114430bb4b0d44"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7dcf6fd8db74192b7ba420aed9eb611"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1bf08bbf7de4d908bf3a0f5037e224f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f61254fc5b75442e83b2135e976a5b42"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51d3d741848e4e64b9dc0e85bdbfbee8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2338c084d05b4832b6a77bc95244c3e8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b596e95991df401ab3995716333d3906"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efc86d5e0ace4947a9849f62bf6b75b8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93a3f0f2af6b40989ec828a8a049ee55"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d956fd129f414475bf2b0d8dd434afe6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1273f3755c94d3f962627f5e6dbc925"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "205e559d4e4349f58e33e87920a8007f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40963ad995b548f6b404e69d13d04406"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "bag_test = []\n",
    "bag_val = []\n",
    "for b in tqdm(range(iteration)):\n",
    "    teacher_forcing = True\n",
    "    loss_store = []\n",
    "    for epoch in tqdm(range(600)):  \n",
    "        # Zero the parameter gradients\n",
    "        enc_opt.zero_grad()\n",
    "        dec_opt.zero_grad()    \n",
    "\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        encoder.train()\n",
    "        decoder.train()\n",
    "\n",
    "        #Mini-batch\n",
    "        x_batch, y_batch, x_sequence, y_sequence = make_batch(batch, xTrain, yTrain, xTrain_seq, yTrain_seq)\n",
    "        x_batch = Variable(torch.from_numpy(x_batch[:,:,:-1]).float().cuda()) # last column is the ID, we dont need it for training\n",
    "\n",
    "        # Encoder\n",
    "        hidden = encoder(x_batch,x_sequence)\n",
    "        hidden = hidden[-1]\n",
    "\n",
    "        # Decoder\n",
    "        if teacher_forcing:\n",
    "            loss = Variable(torch.zeros(1).cuda())\n",
    "            max_seq_length = yTrain.shape[1] # Maximum visits sequence\n",
    "            input = Variable(torch.zeros(batch,1,3).float().cuda()) \n",
    "            for t in range(max_seq_length): #go through each visit sequentially\n",
    "                if more_visit(t,y_sequence):\n",
    "                    y = y_batch[:,:,1:-1]\n",
    "                    y = y[:,t,:]\n",
    "                    y = np.ma.expand_dims(y,1)\n",
    "                    y = Variable(torch.from_numpy(y).cuda()).float()\n",
    "                    hidden, output = decoder(input, h=hidden)\n",
    "                    loss += torch.mul(masked_loss(predicted=output, target=y, sequence=y_sequence, time_step=t),\n",
    "                                     (1/np.max(y_sequence)))\n",
    "                    input = y\n",
    "                    # input to the next sequence is the correct one\n",
    "\n",
    "            loss.backward()\n",
    "            loss_store += [loss.data.cpu().numpy()]\n",
    "            enc_opt.step()\n",
    "            dec_opt.step()\n",
    "            teacher_forcing = False\n",
    "\n",
    "        else:\n",
    "            loss = Variable(torch.zeros(1).cuda())\n",
    "            max_seq_length = yTrain.shape[1] # Maximum visits sequence\n",
    "            input = Variable(torch.zeros(batch,1,3).float().cuda()) \n",
    "            for t in range(max_seq_length): #go through each visit sequentially\n",
    "                if more_visit(t,y_sequence):\n",
    "                    y = y_batch[:,:,1:-1]\n",
    "                    y = y[:,t,:]\n",
    "                    y = np.ma.expand_dims(y,1)\n",
    "                    y = Variable(torch.from_numpy(y).cuda()).float()\n",
    "                    hidden, output = decoder(input, h=hidden)\n",
    "                    loss += torch.mul(masked_loss(predicted=output, target=y, sequence=y_sequence, time_step=t),\n",
    "                                     (1/np.max(y_sequence)))\n",
    "                    input = output.unsqueeze(1)\n",
    "                    # output of this time step becomes the input of the next\n",
    "            loss.backward()\n",
    "            loss_store += [loss.data.cpu().numpy()]\n",
    "            enc_opt.step()\n",
    "            dec_opt.step()\n",
    "\n",
    "            teacher_forcing = True\n",
    "\n",
    "    \"\"\"Val Prediction\"\"\"\n",
    "\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "\n",
    "    x_input = xVal\n",
    "    x_seq_input = xVal_seq\n",
    "    y_input = yVal\n",
    "    y_seq_input = yVal_seq\n",
    "\n",
    "    all_subject_prediction = []\n",
    "    for s in range(x_input.shape[0]):\n",
    "        #Encoder\n",
    "        x = torch.from_numpy(x_input[s])[:,:-1]\n",
    "        x = Variable(x.unsqueeze(0).float(), volatile = True)\n",
    "        x_seq  = x_seq_input[s]\n",
    "        hidden = encoder(x, [x_seq])\n",
    "        hidden = hidden[-1]\n",
    "\n",
    "        #Decoder\n",
    "        y_seq = y_seq_input[s]\n",
    "        input = Variable(torch.zeros(1,1,3).float().cuda(), volatile = True)\n",
    "        individual_pred = []\n",
    "        for t in range(y_seq):\n",
    "            y = y_input[s,:,1:-1]\n",
    "            y = np.ma.expand_dims(y,0)\n",
    "            y = y[:,t,:]\n",
    "            y = np.ma.expand_dims(y,1)\n",
    "            y = Variable(torch.from_numpy(y).cuda(), volatile = True).float()\n",
    "            hidden, output = decoder(input, h=hidden)\n",
    "            input = output.unsqueeze(1)\n",
    "\n",
    "            _, pred = torch.max(output.data, 1)\n",
    "            pred = pred.cpu().numpy()        \n",
    "            individual_pred += [pred]\n",
    "\n",
    "\n",
    "        all_subject_prediction += [np.asarray(individual_pred).flatten()]\n",
    "    all_subject_prediction = np.hstack(all_subject_prediction) \n",
    "    bag_val += [all_subject_prediction]\n",
    "    \n",
    "    \"\"\"Test Prediction\"\"\"\n",
    "\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "\n",
    "    x_input = xTest\n",
    "    x_seq_input = xTest_seq\n",
    "    y_input = yTest\n",
    "    y_seq_input = yTest_seq\n",
    "\n",
    "    all_subject_prediction = []\n",
    "    for s in range(x_input.shape[0]):\n",
    "        #Encoder\n",
    "        x = torch.from_numpy(x_input[s])[:,:-1]\n",
    "        x = Variable(x.unsqueeze(0).float(), volatile = True)\n",
    "        x_seq  = x_seq_input[s]\n",
    "        hidden = encoder(x, [x_seq])\n",
    "        hidden = hidden[-1]\n",
    "\n",
    "        #Decoder\n",
    "        y_seq = y_seq_input[s]\n",
    "        input = Variable(torch.zeros(1,1,3).float().cuda(), volatile = True)\n",
    "        individual_pred = []\n",
    "        for t in range(y_seq):\n",
    "            y = y_input[s,:,1:-1]\n",
    "            y = np.ma.expand_dims(y,0)\n",
    "            y = y[:,t,:]\n",
    "            y = np.ma.expand_dims(y,1)\n",
    "            y = Variable(torch.from_numpy(y).cuda(), volatile = True).float()\n",
    "            hidden, output = decoder(input, h=hidden)\n",
    "            input = output.unsqueeze(1)\n",
    "\n",
    "            _, pred = torch.max(output.data, 1)\n",
    "            pred = pred.cpu().numpy()        \n",
    "            individual_pred += [pred]\n",
    "\n",
    "\n",
    "        all_subject_prediction += [np.asarray(individual_pred).flatten()]\n",
    "    all_subject_prediction = np.hstack(all_subject_prediction)\n",
    "    bag_test += [all_subject_prediction]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging Statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.781938325991\n"
     ]
    }
   ],
   "source": [
    "avg_out= np.round(np.sum(np.vstack(bag_val), axis=0)/iteration)\n",
    "\n",
    "\n",
    "x_input = xVal\n",
    "x_seq_input = xVal_seq\n",
    "y_input = yVal\n",
    "y_seq_input = yVal_seq\n",
    "\n",
    "\"\"\"Target\"\"\"\n",
    "\n",
    "all_subject_target= []\n",
    "for s in range(x_input.shape[0]):\n",
    "    y_seq = y_seq_input[s]\n",
    "    individual_target = []\n",
    "    for t in range(y_seq):\n",
    "        y = y_input[s,:,1:-1]\n",
    "        target = np.argmax(y[t,:])       \n",
    "        individual_target += [target]\n",
    "        \n",
    "    all_subject_target += [np.asarray(individual_target).flatten()]\n",
    "all_subject_target = np.hstack(all_subject_target)\n",
    "\n",
    "\n",
    "accuracy = np.sum(avg_out == all_subject_target)/all_subject_target.shape[0]\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avg_out_val= np.round(np.sum(np.vstack(bag_val), axis=0)/iteration)\n",
    "avg_out_val = avg_out_val.reshape(-1,1)\n",
    "out_val = pd.DataFrame(avg_out_val)\n",
    "out_val.iloc[:,0] =  out_val.iloc[:,0].astype('category')\n",
    "out_val = pd.get_dummies(out_val)\n",
    "out_val = out_val.as_matrix()\n",
    "np.savetxt(\"/home/emy24/tadpole/data/val_class.csv\", out_val ,delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avg_out_test= np.round(np.sum(np.vstack(bag_test), axis=0)/iteration)\n",
    "avg_out_test = avg_out_test.reshape(-1,1)\n",
    "out_test = pd.DataFrame(avg_out_test)\n",
    "out_test.iloc[:,0] =  out_test.iloc[:,0].astype('category')\n",
    "out_test = pd.get_dummies(out_test)\n",
    "out_test = out_test.as_matrix()\n",
    "np.savetxt(\"/home/emy24/tadpole/data/test_class.csv\", out_test ,delimiter=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
