{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"0\"\n",
    "\n",
    "from tools import*\n",
    "from models import*\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from torch.autograd import Variable, Function\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch.nn as nn\n",
    "import nibabel as nib\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data_utils\n",
    "import torch.optim.lr_scheduler as schd  \n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "torch.backends.cudnn.benchmark=True \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch = 32\n",
    "task = \"regression\"\n",
    "iteration = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'resampled_Test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-66b8ace40316>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0mdatapath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/home/emy24/tadpole/data/TADPOLE_PredictTargetData_valid.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0mresampled_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_dates_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresample_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatapath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0myTest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_standarize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresampled_Test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mventricle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0myTest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myTest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0myTest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0myTest\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myTest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0myTest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"PTID_Key\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'resampled_Test' is not defined"
     ]
    }
   ],
   "source": [
    "path = \"/home/emy24/tadpole/data/\"\n",
    "xTrain, xVal, xTest, _, _, _ = preprocess(path,elim_sparse_feature=True, cutoff=0.60)\n",
    "xTrain, xVal, xTest = make_list(path, xTrain, xVal, xTest)\n",
    "\n",
    "# xTrain.to_pickle(\"/home/emy24/tadpole/data/xTrain_pd_60\")\n",
    "# xVal.to_pickle(\"/home/emy24/tadpole/data/xVal_pd_60\")\n",
    "# xTest.to_pickle(\"/home/emy24/tadpole/data/xTest_pd_60\")\n",
    "\n",
    "# xTrain = pd.read_pickle(\"/home/emy24/tadpole/data/xTrain_pd_60\")\n",
    "# xVal = pd.read_pickle(\"/home/emy24/tadpole/data/xVal_pd_60\")\n",
    "# xTest = pd.read_pickle(\"/home/emy24/tadpole/data/xTest_pd_60\")\n",
    "# xTrain, xVal, xTest = make_list(path, xTrain, xVal, xTest)\n",
    "\n",
    "xTrain = get_matrix(xTrain)\n",
    "xTrain, xTrain_seq= get_pad(xTrain)\n",
    "\n",
    "xVal = get_matrix(xVal)\n",
    "xVal, xVal_seq= get_pad(xVal)\n",
    "\n",
    "xTest = get_matrix(xTest)\n",
    "xTest, xTest_seq= get_pad(xTest)\n",
    "\n",
    "\"\"\"Load Target\"\"\"\n",
    "\n",
    "#yTrain\n",
    "datapath = \"/home/emy24/tadpole/data/TADPOLE_TargetData_train.csv\"\n",
    "resampled_train, orig_dates_train = resample_data(datapath, interpolation = True)\n",
    "adas, ventricle, mmse = get_average(resampled_train)\n",
    "yTrain = get_standarize(resampled_train, adas, ventricle, mmse)\n",
    "yTrain = get_features(yTrain, task)\n",
    "yTrain = [yTrain for _, yTrain in yTrain.groupby(\"PTID_Key\")]\n",
    "yTrain = get_matrix(yTrain)\n",
    "yTrain, yTrain_seq= get_pad(yTrain)\n",
    "\n",
    "#yVal\n",
    "datapath = \"/home/emy24/tadpole/data/TADPOLE_TargetData_test.csv\"\n",
    "resampled_val, orig_dates_val = resample_data(datapath, interpolation = True)\n",
    "yVal = get_standarize(resampled_val, adas, ventricle, mmse)\n",
    "yVal = get_features(yVal, task)\n",
    "yVal = [yVal for _, yVal in yVal.groupby(\"PTID_Key\")]\n",
    "yVal = get_matrix(yVal)\n",
    "yVal, yVal_seq= get_pad(yVal)\n",
    "\n",
    "#yTest\n",
    "datapath = \"/home/emy24/tadpole/data/TADPOLE_PredictTargetData_valid.csv\"\n",
    "resampled_test, orig_dates_test = resample_data(datapath, interpolation = True)\n",
    "resampled_test = resampled_test.fillna(0)\n",
    "yTest = get_standarize(resampled_test, adas, ventricle, mmse)\n",
    "yTest = get_features(yTest, task)\n",
    "yTest = [yTest for _, yTest in yTest.groupby(\"PTID_Key\")]\n",
    "yTest = get_matrix(yTest)\n",
    "yTest, yTest_seq= get_pad(yTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def masked_loss(predicted, target, sequence, time_step):\n",
    "    \"\"\"\n",
    "    sequence: is the total numbers of visit from a patient\n",
    "    time_step: is the current visit\n",
    "    ----\n",
    "    ind: indicates whether we have information about the patient at this time step\n",
    "    k: number of elements in M that we actually care/have information. \n",
    "    loss: (1/k)*sum(ind*M)\n",
    "    Note:\n",
    "    squeeze at the beggining is to make sure to have a nxm matrix instead of a 3d tensor\n",
    "    the unsqueze thing in loss is just to make the matrix have the correct format for bmm function\n",
    "    \"\"\"\n",
    "    predicted = predicted.squeeze()\n",
    "    target = target.squeeze()\n",
    "    ind = ((time_step < np.asarray(sequence))*1).reshape(1,-1)\n",
    "    num_features = predicted.size(1)\n",
    "    k = np.sum(ind*num_features)\n",
    "    ind = Variable(torch.from_numpy(ind).cuda(), requires_grad = False).float()\n",
    "    M = torch.abs(predicted - target)\n",
    "    loss = torch.mul(torch.sum(torch.mm(ind, M)),(1/k))\n",
    "    return loss\n",
    "\n",
    "def get_accuracy(output, y_batch, t):\n",
    "    _, pred = torch.max(output.data, 1)\n",
    "    pred = pred.cpu().numpy()\n",
    "    label = y_batch[:,:,:]\n",
    "    label = label[:,t,-1]\n",
    "    correct = np.sum(pred==label)\n",
    "    \n",
    "    return 100*correct/label.shape[0]\n",
    "\n",
    "def more_visit(time_step,sequence):\n",
    "    return (np.sum((time_step < np.asarray(y_sequence))*1) > 0)\n",
    "\n",
    "\"\"\"GRU\"\"\"\n",
    "class GRU_Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, batch):\n",
    "        super(GRU_Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.batch = batch\n",
    "        self.gru = nn.GRU(input_size = input_size, hidden_size = hidden_size,\n",
    "                            batch_first=True, num_layers = num_layers)\n",
    "    \n",
    "    def forward(self, x, seq):\n",
    "        # Set initial states\n",
    "        h0 = Variable(torch.randn(self.num_layers, self.batch, self.hidden_size).float().cuda())\n",
    "        \n",
    "        # Forward propagate RNN\n",
    "        x = pack_padded_sequence(x, seq, batch_first=True)\n",
    "        out, hidden = self.gru(x)  \n",
    "        return out, hidden\n",
    "    \n",
    "\n",
    "class GRU_Decoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, batch, num_classes):\n",
    "        super(GRU_Decoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.batch = batch\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(in_features= self.hidden_size, out_features= self.hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(in_features= self.hidden_size, out_features= self.hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(in_features= self.hidden_size, out_features= 3))\n",
    " \n",
    "    def forward(self, x, h):    \n",
    "        # Forward propagate RNN\n",
    "        _, hidden = self.gru(x, h)\n",
    "        out = hidden[-1] #Grab the last output of the sequence\n",
    "        out = self.fc(out)  \n",
    "        return hidden, out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder = GRU_Encoder(input_size = 431 , hidden_size = 100, num_layers= 3, batch = batch )\n",
    "encoder = torch.nn.DataParallel(encoder)\n",
    "encoder.cuda()\n",
    "\n",
    "decoder = GRU_Decoder(input_size = 3 , hidden_size = 100, num_layers= 3, batch= batch, num_classes = 3)\n",
    "decoder = torch.nn.DataParallel(decoder)\n",
    "decoder.cuda()\n",
    "\n",
    "# Loss and Optimizer\n",
    "enc_opt = optim.Adam(encoder.parameters())\n",
    "dec_opt = optim.Adam(decoder.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fe30f24956c4e6a8b04db31e7bc274f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6cc82ca68f5402486c6fc1d076d0fee"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95deaa72e3e44e18a005aeb6e99b01ba"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ce4c49fa595495c80db933c19cfa4be"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e4abfffa9594dc0ad081d3b281ff338"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7318f7c95a5b4202bca50c5c4aea84f9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "224e5dd157554ed59d3b3994e2fa70d2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "396e37c399234adf92eb503ff076ae69"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc28e5e520704587962f4fe38d918911"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b12385cf4e4420a9a1fed35cf8b3848"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d71fcbe814a548f5b12d14c0c1e0b188"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c0872e45f7e4503846d0560ab6cf3d1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af7cefc3cad84697b66de16e25de0f45"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31cf84d61b1a46fa91ef86fc403e163e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56ca94de85d548fb9092a3ebcd8d7c86"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02218b27d4c2420cae2482afdda343fc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9303b1acce6b4f2fb6fac1bcbcc9ac5f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "504214414c43424a8bceb25db235d5c0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39bcbe537de24dbfb3235f6766459188"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d90efca992fb4a469971751ffc670c38"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "194843de45c746a59e5363c31c4373bb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eee9e59be9447d195d1a286d0faad8d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1021dc590ec46cb8f06bb7b986039e8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d960a6aeaa24b70b1a3a178feea3d6b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f3cb57d44ea48068c2d8500c2f43534"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "139bb8f0429041a08d0b27e0dca3ef1a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07c79bbfbd3341df84c55fd84ff80e16"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b2da9eb74224c9aa9706c1df97ae236"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ff9e50f6fd04aa4b075f47f17c5f632"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "757b8ec30d71487eb7eeedee36528de5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c20bd34f1fe4059acc4ada7d6f24109"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2501d017cbf445128643c934d18a9cb8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d41d10bac8b42fea94266616933b16f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "779a310746284658a844929c61975f9a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "787df27fe55a4b46a0b0890acaa07def"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24111c7056114b5aa43938a115356de6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5e11c6122034508bd3f7b73ee89e9d7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f5b17cdcab743a3af09f9dc9739053d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1a2f5c9bed548bf982346118174a638"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bae51dea7d34c5bb0ea4ba62a7da312"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73a2504962444f59822dcb016be55f10"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "218bd49e8cef4d85bec69a0ccfddc0e5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e52515e1a63e4cb1838feb6f59a27515"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c04014240eb498cb1f6e40cae99d87e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4ee8a27c307412b95654acc43f08660"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d62a5a65f3b41ae8024b3b38cfb2911"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63e0494306b84b4aa7089fcf906d5e53"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5a6d50d3e004a3e919c6739512f8970"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e36b77ee805f444e82ee32ef346c088d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69cb1f0c444d4f3297c549ea01c4b3f7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb5f2527e1534f50bec938228e4c5096"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "bag_test = []\n",
    "bag_val = []\n",
    "for b in tqdm(range(iteration)):\n",
    "    teacher_forcing = True\n",
    "    loss_store = []\n",
    "    for epoch in tqdm(range(600)):  \n",
    "        # Zero the parameter gradients\n",
    "        enc_opt.zero_grad()\n",
    "        dec_opt.zero_grad()    \n",
    "\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        encoder.train()\n",
    "        decoder.train()\n",
    "\n",
    "        #Mini-batch\n",
    "        x_batch, y_batch, x_sequence, y_sequence = make_batch(batch, xTrain, yTrain, xTrain_seq, yTrain_seq)\n",
    "        x_batch = Variable(torch.from_numpy(x_batch[:,:,:-1]).float().cuda()) # last column is the ID, we dont need it for training\n",
    "\n",
    "        # Encoder\n",
    "        hidden = encoder(x_batch,x_sequence)\n",
    "        hidden = hidden[-1]\n",
    "\n",
    "        # Decoder\n",
    "        if teacher_forcing:\n",
    "            loss = Variable(torch.zeros(1).cuda())\n",
    "            max_seq_length = yTrain.shape[1] # Maximum visits sequence\n",
    "            input = Variable(torch.zeros(batch,1,3).float().cuda()) \n",
    "            for t in range(max_seq_length): #go through each visit sequentially\n",
    "                if more_visit(t,y_sequence):\n",
    "                    y = y_batch[:,:,1:]\n",
    "                    y = y[:,t,:]\n",
    "                    y = np.ma.expand_dims(y,1)\n",
    "                    y = Variable(torch.from_numpy(y).cuda()).float()\n",
    "                    hidden, output = decoder(input, h=hidden)\n",
    "                    loss += torch.mul(masked_loss(predicted=output, target=y, sequence=y_sequence, time_step=t),\n",
    "                                     (1/np.max(y_sequence)))\n",
    "                    input = y\n",
    "                    # input to the next sequence is the correct one\n",
    "\n",
    "            loss.backward()\n",
    "            loss_store += [loss.data.cpu().numpy()]\n",
    "            enc_opt.step()\n",
    "            dec_opt.step()\n",
    "            teacher_forcing = False\n",
    "\n",
    "        else:\n",
    "            loss = Variable(torch.zeros(1).cuda())\n",
    "            max_seq_length = yTrain.shape[1] # Maximum visits sequence\n",
    "            input = Variable(torch.zeros(batch,1,3).float().cuda()) \n",
    "            for t in range(max_seq_length): #go through each visit sequentially\n",
    "                if more_visit(t,y_sequence):\n",
    "                    y = y_batch[:,:,1:]\n",
    "                    y = y[:,t,:]\n",
    "                    y = np.ma.expand_dims(y,1)\n",
    "                    y = Variable(torch.from_numpy(y).cuda()).float()\n",
    "                    hidden, output = decoder(input, h=hidden)\n",
    "                    loss += torch.mul(masked_loss(predicted=output, target=y, sequence=y_sequence, time_step=t),\n",
    "                                     (1/np.max(y_sequence)))\n",
    "                    input = output.unsqueeze(1)\n",
    "                    # output of this time step becomes the input of the next\n",
    "            loss.backward()\n",
    "            loss_store += [loss.data.cpu().numpy()]\n",
    "            enc_opt.step()\n",
    "            dec_opt.step()\n",
    "\n",
    "            teacher_forcing = True\n",
    "\n",
    "    \"\"\"Validation\"\"\"\n",
    "\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "\n",
    "    x_input = xVal\n",
    "    x_seq_input = xVal_seq\n",
    "    y_input = yVal\n",
    "    y_seq_input = yVal_seq\n",
    "\n",
    "    \"\"\"Prediction\"\"\"\n",
    "    all_subject_prediction = []\n",
    "    for s in range(x_input.shape[0]):\n",
    "        #Encoder\n",
    "        x = torch.from_numpy(x_input[s])[:,:-1]\n",
    "        x = Variable(x.unsqueeze(0).float(), volatile = True)\n",
    "        x_seq  = x_seq_input[s]\n",
    "        hidden = encoder(x, [x_seq])\n",
    "        hidden = hidden[-1]\n",
    "\n",
    "        #Decoder\n",
    "        y_seq = y_seq_input[s]\n",
    "        input = Variable(torch.zeros(1,1,3).float().cuda(), volatile = True)\n",
    "        individual_pred = []\n",
    "        for t in range(y_seq):\n",
    "            y = y_input[s,:,1:]\n",
    "            y = np.ma.expand_dims(y,0)\n",
    "            y = y[:,t,:]\n",
    "            y = np.ma.expand_dims(y,1)\n",
    "            y = Variable(torch.from_numpy(y).cuda(), volatile = True).float()\n",
    "            hidden, output = decoder(input, h=hidden)\n",
    "            input = output.unsqueeze(1)\n",
    "\n",
    "            pred = output.data\n",
    "            pred = pred.cpu().numpy()        \n",
    "            individual_pred += [pred]\n",
    "\n",
    "\n",
    "        all_subject_prediction += [np.vstack(individual_pred)]\n",
    "    all_subject_prediction = np.vstack(all_subject_prediction) \n",
    "    bag_val += [all_subject_prediction]\n",
    "    \n",
    "    \"\"\"Test\"\"\"\n",
    "    \n",
    "    x_input = xTest\n",
    "    x_seq_input = xTest_seq\n",
    "    y_input = yTest\n",
    "    y_seq_input = yTest_seq    \n",
    "    \n",
    "    all_subject_prediction = []\n",
    "    for s in range(x_input.shape[0]):\n",
    "        #Encoder\n",
    "        x = torch.from_numpy(x_input[s])[:,:-1]\n",
    "        x = Variable(x.unsqueeze(0).float(), volatile = True)\n",
    "        x_seq  = x_seq_input[s]\n",
    "        hidden = encoder(x, [x_seq])\n",
    "        hidden = hidden[-1]\n",
    "\n",
    "        #Decoder\n",
    "        y_seq = y_seq_input[s]\n",
    "        input = Variable(torch.zeros(1,1,3).float().cuda(), volatile = True)\n",
    "        individual_pred = []\n",
    "        for t in range(y_seq):\n",
    "            y = y_input[s,:,1:]\n",
    "            y = np.ma.expand_dims(y,0)\n",
    "            y = y[:,t,:]\n",
    "            y = np.ma.expand_dims(y,1)\n",
    "            y = Variable(torch.from_numpy(y).cuda(), volatile = True).float()\n",
    "            hidden, output = decoder(input, h=hidden)\n",
    "            input = output.unsqueeze(1)\n",
    "\n",
    "            pred = output.data\n",
    "            pred = pred.cpu().numpy()        \n",
    "            individual_pred += [pred]\n",
    "\n",
    "\n",
    "        all_subject_prediction += [np.vstack(individual_pred)]\n",
    "    all_subject_prediction = np.vstack(all_subject_prediction) \n",
    "    bag_test += [all_subject_prediction]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistic after bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.99951515538\n",
      "0.0047583244545\n",
      "1.67627591563\n"
     ]
    }
   ],
   "source": [
    "avg_out_val= np.sum(np.dstack(bag_val), axis=2)/iteration\n",
    "\n",
    "\"\"\"Target\"\"\"\n",
    "\n",
    "x_input = xVal\n",
    "x_seq_input = xVal_seq\n",
    "y_input = yVal\n",
    "y_seq_input = yVal_seq\n",
    "\n",
    "all_subject_target= []\n",
    "for s in range(x_input.shape[0]):\n",
    "    y_seq = y_seq_input[s]\n",
    "    individual_target = []\n",
    "    for t in range(y_seq):\n",
    "        y = y_input[s,:,1:]\n",
    "        target = y[t,:]       \n",
    "        individual_target += [target]\n",
    "\n",
    "    all_subject_target += [np.vstack(individual_target)]\n",
    "all_subject_target = np.vstack(all_subject_target)\n",
    "\n",
    "\"\"\"Get rid of standarization\"\"\"\n",
    "\n",
    "all_subject_target[:,0] = all_subject_target[:,0]*adas[1]+adas[0]\n",
    "all_subject_target[:,1] = all_subject_target[:,1]*ventricle[1]+ventricle[0]\n",
    "all_subject_target[:,2] = all_subject_target[:,2]*mmse[1]+mmse[0]\n",
    "\n",
    "avg_out[:,0] = avg_out[:,0]*adas[1]+adas[0]\n",
    "avg_out[:,1] = avg_out[:,1]*ventricle[1]+ventricle[0]\n",
    "avg_out[:,2] = avg_out[:,2]*mmse[1]+mmse[0]\n",
    "\n",
    "adas_mae = mean_absolute_error(all_subject_target[:,0], avg_out[:,0])\n",
    "vent_mae = mean_absolute_error(all_subject_target[:,1], avg_out[:,1])\n",
    "mmse_mae = mean_absolute_error(all_subject_target[:,2], avg_out[:,2])\n",
    "\n",
    "print(adas_mae)\n",
    "print(vent_mae)\n",
    "print(mmse_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "avg_out_val= np.sum(np.dstack(bag_val), axis=2)/iteration\n",
    "avg_out_val[:,0] = avg_out_val[:,0]*adas[1]+adas[0]\n",
    "avg_out_val[:,1] = avg_out_val[:,1]*ventricle[1]+ventricle[0]\n",
    "avg_out_val[:,2] = avg_out_val[:,2]*mmse[1]+mmse[0]\n",
    "np.savetxt(\"/home/emy24/tadpole/data/val_pred.csv\", avg_out_val,delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_out_test= np.sum(np.dstack(bag_test), axis=2)/iteration\n",
    "avg_out_test[:,0] = avg_out_test[:,0]*adas[1]+adas[0]\n",
    "avg_out_test[:,1] = avg_out_test[:,1]*ventricle[1]+ventricle[0]\n",
    "avg_out_test[:,2] = avg_out_test[:,2]*mmse[1]+mmse[0]\n",
    "np.savetxt(\"/home/emy24/tadpole/data/test_pred.csv\", avg_out_test ,delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_subject = resampled_val[\"PTID_Key\"].as_matrix()\n",
    "np.savetxt(\"/home/emy24/tadpole/data/val_subject.csv\", val_subject,delimiter=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
